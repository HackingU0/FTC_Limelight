{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-23T02:46:22.106318Z",
          "start_time": "2025-03-23T02:46:16.102581Z"
        },
        "collapsed": true,
        "id": "initial_id",
        "outputId": "3afd6a3e-04e6-4504-db03-aab62c0fe850"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2358.36s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: tensorflow 2.16.2\n",
            "Uninstalling tensorflow-2.16.2:\n",
            "  Successfully uninstalled tensorflow-2.16.2\n",
            "Found existing installation: tensorflow-macos 2.16.2\n",
            "Uninstalling tensorflow-macos-2.16.2:\n",
            "  Successfully uninstalled tensorflow-macos-2.16.2\n",
            "Found existing installation: tensorflow-metal 1.2.0\n",
            "Uninstalling tensorflow-metal-1.2.0:\n",
            "  Successfully uninstalled tensorflow-metal-1.2.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2365.15s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-macos\n",
            "  Using cached tensorflow_macos-2.16.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
            "Collecting tensorflow==2.16.2 (from tensorflow-macos)\n",
            "  Using cached tensorflow-2.16.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.3.0)\n",
            "Requirement already satisfied: packaging in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (75.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2->tensorflow-macos) (0.45.1)\n",
            "Requirement already satisfied: rich in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (13.9.4)\n",
            "Requirement already satisfied: namex in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.0.7)\n",
            "Requirement already satisfied: optree in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.1.0)\n",
            "Using cached tensorflow_macos-2.16.2-cp312-cp312-macosx_12_0_arm64.whl (2.1 kB)\n",
            "Using cached tensorflow-2.16.2-cp312-cp312-macosx_12_0_arm64.whl (227.1 MB)\n",
            "Installing collected packages: tensorflow, tensorflow-macos\n",
            "Successfully installed tensorflow-2.16.2 tensorflow-macos-2.16.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2377.37s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (1.26.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2383.11s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2388.85s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2394.64s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Keras in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (3.6.0)\n",
            "Requirement already satisfied: absl-py in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from Keras) (2.1.0)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from Keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from Keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from Keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from Keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from Keras) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from Keras) (0.3.2)\n",
            "Requirement already satisfied: packaging in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from Keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from optree->Keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from rich->Keras) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from rich->Keras) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->Keras) (0.1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2400.44s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2406.22s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-metal\n",
            "  Using cached tensorflow_metal-1.2.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow-metal) (0.45.1)\n",
            "Requirement already satisfied: six>=1.15.0 in /opt/homebrew/anaconda3/envs/FTC_Limelight/lib/python3.12/site-packages (from tensorflow-metal) (1.16.0)\n",
            "Using cached tensorflow_metal-1.2.0-cp312-cp312-macosx_12_0_arm64.whl (1.4 MB)\n",
            "Installing collected packages: tensorflow-metal\n",
            "Successfully installed tensorflow-metal-1.2.0\n"
          ]
        }
      ],
      "source": [
        "#install requirements\n",
        "!pip install tensorflow\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install opencv-python\n",
        "!pip install Keras\n",
        "!pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb88e853",
      "metadata": {
        "id": "fb88e853",
        "outputId": "a65e29fb-7b75-49eb-bc61-01b5279aec66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow版本: 2.16.2\n",
            "可用设备: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow版本:\", tf.__version__)\n",
        "print(\"可用设备:\", tf.config.list_physical_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd7aff1f9886419",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-23T02:55:11.461988Z",
          "start_time": "2025-03-23T02:55:11.459523Z"
        },
        "id": "cbd7aff1f9886419"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import models, layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c03418f9007793bf",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-03-23T03:07:04.484705Z"
        },
        "jupyter": {
          "is_executing": true
        },
        "id": "c03418f9007793bf",
        "outputId": "77451d3d-4cba-46e1-dc85-9c1d0de22947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "训练集CSV包含 3378 条记录\n",
            "验证集CSV包含 307 条记录\n",
            "处理了 100/3378 条记录\n",
            "处理了 200/3378 条记录\n",
            "处理了 300/3378 条记录\n",
            "处理了 400/3378 条记录\n",
            "处理了 500/3378 条记录\n",
            "处理了 600/3378 条记录\n",
            "处理了 700/3378 条记录\n",
            "处理了 800/3378 条记录\n",
            "处理了 900/3378 条记录\n",
            "处理了 1000/3378 条记录\n",
            "处理了 1100/3378 条记录\n",
            "处理了 1200/3378 条记录\n",
            "处理了 1300/3378 条记录\n",
            "处理了 1400/3378 条记录\n",
            "处理了 1500/3378 条记录\n",
            "处理了 1600/3378 条记录\n",
            "处理了 1700/3378 条记录\n",
            "处理了 1800/3378 条记录\n",
            "处理了 1900/3378 条记录\n",
            "处理了 2000/3378 条记录\n",
            "处理了 2100/3378 条记录\n",
            "处理了 2200/3378 条记录\n",
            "处理了 2300/3378 条记录\n",
            "处理了 2400/3378 条记录\n",
            "处理了 2500/3378 条记录\n",
            "处理了 2600/3378 条记录\n",
            "处理了 2700/3378 条记录\n",
            "处理了 2800/3378 条记录\n",
            "处理了 2900/3378 条记录\n",
            "处理了 3000/3378 条记录\n",
            "处理了 3100/3378 条记录\n",
            "处理了 3200/3378 条记录\n",
            "处理了 3300/3378 条记录\n",
            "有效条目: 3378/3378\n",
            "处理了 100/307 条记录\n",
            "处理了 200/307 条记录\n",
            "处理了 300/307 条记录\n",
            "有效条目: 307/307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:51:48.527979: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
            "2025-03-22 23:51:48.528030: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
            "2025-03-22 23:51:48.528034: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
            "2025-03-22 23:51:48.528077: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2025-03-22 23:51:48.528097: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "训练数据集大小: 3378\n",
            "验证数据集大小: 307\n",
            "\n",
            "训练数据集示例:\n",
            "批次大小: 32\n",
            "图像形状: (32, 640, 640, 3)\n",
            "标签示例: [0 1 0]\n",
            "边界框示例: [[0.428125  0.390625  0.6140625 0.6234375]\n",
            " [0.1703125 0.3546875 0.278125  0.615625 ]\n",
            " [0.4       0.3640625 0.603125  0.578125 ]]\n",
            "\n",
            "验证数据集示例:\n",
            "批次大小: 32\n",
            "图像形状: (32, 640, 640, 3)\n",
            "标签示例: [0 2 1]\n",
            "边界框示例: [[0.475     0.1546875 0.6296875 0.3625   ]\n",
            " [0.3546875 0.509375  0.584375  0.7671875]\n",
            " [0.575     0.396875  0.753125  0.690625 ]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:51:51.690629: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:51:51.771225: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "# 加载训练集和验证集（位于不同目录）\n",
        "\n",
        "# 训练集路径\n",
        "train_base_dir = Path('./FTC Sample Detection.v2i.tensorflow/train')\n",
        "train_annotations = pd.read_csv(train_base_dir / '_annotations.csv')\n",
        "train_total_rows = len(train_annotations)\n",
        "print(f\"训练集CSV包含 {train_total_rows} 条记录\")\n",
        "\n",
        "# 验证集路径 - 请替换为你的实际验证集路径\n",
        "val_base_dir = Path('./FTC Sample Detection.v2i.tensorflow/valid') # 根据实际路径修改\n",
        "val_annotations = pd.read_csv(val_base_dir / '_annotations.csv')\n",
        "val_total_rows = len(val_annotations)\n",
        "print(f\"验证集CSV包含 {val_total_rows} 条记录\")\n",
        "\n",
        "# 类别映射\n",
        "class_mapping = {\n",
        "    'blue sample': 0,\n",
        "    'red sample': 1,\n",
        "    'yellow sample': 2\n",
        "}\n",
        "\n",
        "# 处理数据集的函数\n",
        "def process_dataset(annotations, base_dir, class_mapping):\n",
        "    valid_entries = []\n",
        "    total_rows = len(annotations)\n",
        "\n",
        "    for i, row in annotations.iterrows():\n",
        "        image_path = base_dir / row['filename']\n",
        "        class_name = row['class']\n",
        "        class_id = class_mapping.get(class_name, -1)\n",
        "\n",
        "        if os.path.exists(image_path) and class_id != -1:\n",
        "            # 创建数据条目\n",
        "            entry = {\n",
        "                'image_path': str(image_path),\n",
        "                'class_id': class_id,\n",
        "                'bbox': [\n",
        "                    row['xmin'] / row['width'],\n",
        "                    row['ymin'] / row['height'],\n",
        "                    row['xmax'] / row['width'],\n",
        "                    row['ymax'] / row['height']\n",
        "                ],\n",
        "                'width': row['width'],\n",
        "                'height': row['height']\n",
        "            }\n",
        "            valid_entries.append(entry)\n",
        "\n",
        "        # 进度显示\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f\"处理了 {i+1}/{total_rows} 条记录\")\n",
        "\n",
        "    print(f\"有效条目: {len(valid_entries)}/{total_rows}\")\n",
        "    return valid_entries\n",
        "\n",
        "# 处理训练集和验证集\n",
        "train_entries = process_dataset(train_annotations, train_base_dir, class_mapping)\n",
        "val_entries = process_dataset(val_annotations, val_base_dir, class_mapping)\n",
        "\n",
        "# 解析函数\n",
        "def parse_function(entry):\n",
        "    # 读取图像\n",
        "    image_path = entry['image_path']\n",
        "    img_raw = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_image(img_raw, channels=3, expand_animations=False)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)  # 归一化到 [0,1]\n",
        "\n",
        "    # 提取标签和边界框\n",
        "    label = entry['class_id']\n",
        "    bbox = entry['bbox']\n",
        "\n",
        "    return image, (label, bbox)\n",
        "\n",
        "# 创建训练集\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: train_entries,\n",
        "    output_signature={\n",
        "        'image_path': tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        'class_id': tf.TensorSpec(shape=(), dtype=tf.int32),\n",
        "        'bbox': tf.TensorSpec(shape=(4,), dtype=tf.float32),\n",
        "        'width': tf.TensorSpec(shape=(), dtype=tf.int32),\n",
        "        'height': tf.TensorSpec(shape=(), dtype=tf.int32)\n",
        "    }\n",
        ")\n",
        "train_dataset = train_dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# 创建验证集\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: val_entries,\n",
        "    output_signature={\n",
        "        'image_path': tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "        'class_id': tf.TensorSpec(shape=(), dtype=tf.int32),\n",
        "        'bbox': tf.TensorSpec(shape=(4,), dtype=tf.float32),\n",
        "        'width': tf.TensorSpec(shape=(), dtype=tf.int32),\n",
        "        'height': tf.TensorSpec(shape=(), dtype=tf.int32)\n",
        "    }\n",
        ")\n",
        "val_dataset = val_dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# 批处理、预取优化\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_entries)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(f\"训练数据集大小: {len(train_entries)}\")\n",
        "print(f\"验证数据集大小: {len(val_entries)}\")\n",
        "\n",
        "# 检查数据集\n",
        "print(\"\\n训练数据集示例:\")\n",
        "for images, (labels, bboxes) in train_dataset.take(1):\n",
        "    print(f\"批次大小: {images.shape[0]}\")\n",
        "    print(f\"图像形状: {images.shape}\")\n",
        "    print(f\"标签示例: {labels[:3].numpy()}\")\n",
        "    print(f\"边界框示例: {bboxes[:3].numpy()}\")\n",
        "\n",
        "print(\"\\n验证数据集示例:\")\n",
        "for images, (labels, bboxes) in val_dataset.take(1):\n",
        "    print(f\"批次大小: {images.shape[0]}\")\n",
        "    print(f\"图像形状: {images.shape}\")\n",
        "    print(f\"标签示例: {labels[:3].numpy()}\")\n",
        "    print(f\"边界框示例: {bboxes[:3].numpy()}\")\n",
        "\n",
        "# 预处理数据集\n",
        "def preprocess_dataset(dataset, input_shape=(224, 224)):\n",
        "    def resize_image(image, label_bbox):\n",
        "        image = tf.image.resize(image, input_shape)\n",
        "        return image, label_bbox\n",
        "\n",
        "    return dataset.map(resize_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# 应用预处理\n",
        "train_dataset = preprocess_dataset(train_dataset)\n",
        "val_dataset = preprocess_dataset(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c06c7c41395ff6c",
      "metadata": {
        "id": "5c06c7c41395ff6c",
        "outputId": "9d45531b-e432-406d-8498-a26f86c7805f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ true_divide         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TrueDivide</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ true_divide[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mobilenetv2_1.00_2… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │ subtract[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mobilenetv2_1.00… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classification      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bbox_regression     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ true_divide         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mTrueDivide\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ subtract (\u001b[38;5;33mSubtract\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ true_divide[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mobilenetv2_1.00_2… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m2,257,984\u001b[0m │ subtract[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m1280\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ mobilenetv2_1.00… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m327,936\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ classification      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m771\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bbox_regression     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │      \u001b[38;5;34m1,028\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,587,719</span> (9.87 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,587,719\u001b[0m (9.87 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,191,175</span> (8.36 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,191,175\u001b[0m (8.36 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,544</span> (1.51 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m396,544\u001b[0m (1.51 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Framework\n",
        "\n",
        "def create_detection_model(input_shape=(224,224,3),num_classes=3):\n",
        "\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "\n",
        "    for layer in base_model.layers[:100]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs*255.0)\n",
        "    x = base_model(x,training = False)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(256,activation='relu')(x)\n",
        "\n",
        "    classification_output = layers.Dense(num_classes,activation=\"softmax\",name = \"classification\")(x)\n",
        "    bbox_output = layers.Dense(4,name='bbox_regression')(x)\n",
        "    model = models.Model(inputs=inputs,outputs=[classification_output,bbox_output])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Compile\n",
        "def bbox_loss(y_true,y_pred):\n",
        "    return tf.keras.losses.Huber()(y_true,y_pred)\n",
        "\n",
        "input_shape = (224,224,3)\n",
        "model = create_detection_model(input_shape=input_shape,num_classes=3)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss={\n",
        "        'classification': 'sparse_categorical_crossentropy',  # 这是正确的\n",
        "        'bbox_regression': 'mse'  # 边界框用均方误差损失\n",
        "    },\n",
        "    metrics={\n",
        "        'classification': 'accuracy',\n",
        "        'bbox_regression': tf.keras.metrics.MeanAbsoluteError()\n",
        "    }\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "900cff06",
      "metadata": {
        "id": "900cff06"
      },
      "outputs": [],
      "source": [
        "\n",
        "# preprocess dataset\n",
        "def preprocess_dataset(dataset,input_shape=(224,224)):\n",
        "    def resize_image(image,label_bbox):\n",
        "        image = tf.image.resize(image,input_shape)\n",
        "        return image,label_bbox\n",
        "\n",
        "    return dataset.map(resize_image,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset = preprocess_dataset(train_dataset)\n",
        "val_dataset = preprocess_dataset(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29be9709",
      "metadata": {
        "id": "29be9709",
        "outputId": "aac2aa8e-7be1-43f9-e5cb-50ab33023282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:52:11.561526: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
            "2025-03-22 23:52:11.579852: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] PluggableGraphOptimizer failed: INVALID_ARGUMENT: Failed to deserialize the `graph_buf`.\n",
            "2025-03-22 23:52:54.250360: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:53:00.815990: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 9.8701\n",
            "Epoch 1/30 - Loss: 0.6946, Class Loss: 0.5984, Bbox Loss: 0.0963 - Val Loss: 9.8701, Val Class Loss: 2.4998, Val Bbox Loss: 7.3704, Val Class Acc: 0.4347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:53:25.184176: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:53:25.955544: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 4.6962\n",
            "Epoch 2/30 - Loss: 0.5679, Class Loss: 0.5289, Bbox Loss: 0.0390 - Val Loss: 4.6962, Val Class Loss: 2.4227, Val Bbox Loss: 2.2736, Val Class Acc: 0.3285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:53:50.240626: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:53:51.030481: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 2.5609\n",
            "Epoch 3/30 - Loss: 0.5594, Class Loss: 0.5273, Bbox Loss: 0.0321 - Val Loss: 2.5609, Val Class Loss: 0.6304, Val Bbox Loss: 1.9305, Val Class Acc: 0.7018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:54:15.131769: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:54:15.908147: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/30 - Loss: 0.5446, Class Loss: 0.5155, Bbox Loss: 0.0291 - Val Loss: 3.3498, Val Class Loss: 0.6937, Val Bbox Loss: 2.6560, Val Class Acc: 0.7049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:54:38.771511: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:54:39.586791: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 1.8677\n",
            "Epoch 5/30 - Loss: 0.5463, Class Loss: 0.5184, Bbox Loss: 0.0280 - Val Loss: 1.8677, Val Class Loss: 0.6328, Val Bbox Loss: 1.2349, Val Class Acc: 0.6737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:55:03.777055: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:55:04.547946: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 1.7983\n",
            "Epoch 6/30 - Loss: 0.5457, Class Loss: 0.5182, Bbox Loss: 0.0275 - Val Loss: 1.7983, Val Class Loss: 0.9986, Val Bbox Loss: 0.7997, Val Class Acc: 0.5757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:55:26.891637: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:55:27.623798: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/30 - Loss: 0.5433, Class Loss: 0.5183, Bbox Loss: 0.0250 - Val Loss: 2.9924, Val Class Loss: 2.5291, Val Bbox Loss: 0.4633, Val Class Acc: 0.4775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:55:49.516132: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:55:50.276611: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/30 - Loss: 0.5637, Class Loss: 0.5379, Bbox Loss: 0.0258 - Val Loss: 7.5016, Val Class Loss: 6.8699, Val Bbox Loss: 0.6316, Val Class Acc: 0.2877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:56:12.584661: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:56:13.370373: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/30 - Loss: 0.5296, Class Loss: 0.5065, Bbox Loss: 0.0230 - Val Loss: 4.9563, Val Class Loss: 4.5293, Val Bbox Loss: 0.4270, Val Class Acc: 0.3169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:56:35.650108: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:56:36.497833: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/30 - Loss: 0.5249, Class Loss: 0.5037, Bbox Loss: 0.0212 - Val Loss: 2.3120, Val Class Loss: 1.8496, Val Bbox Loss: 0.4624, Val Class Acc: 0.4870\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:57:00.436175: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:57:01.206714: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/30 - Loss: 0.5199, Class Loss: 0.4995, Bbox Loss: 0.0204 - Val Loss: 5.3827, Val Class Loss: 5.0701, Val Bbox Loss: 0.3125, Val Class Acc: 0.4462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:57:23.823136: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:57:24.575066: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 1.0683\n",
            "Epoch 12/30 - Loss: 0.5199, Class Loss: 0.4997, Bbox Loss: 0.0201 - Val Loss: 1.0683, Val Class Loss: 0.8369, Val Bbox Loss: 0.2314, Val Class Acc: 0.6038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:57:47.538899: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:57:48.315189: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 0.8639\n",
            "Epoch 13/30 - Loss: 0.5189, Class Loss: 0.4989, Bbox Loss: 0.0200 - Val Loss: 0.8639, Val Class Loss: 0.6371, Val Bbox Loss: 0.2268, Val Class Acc: 0.7049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:58:11.228311: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:58:12.050811: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 0.6532\n",
            "Epoch 14/30 - Loss: 0.5109, Class Loss: 0.4923, Bbox Loss: 0.0186 - Val Loss: 0.6532, Val Class Loss: 0.5151, Val Bbox Loss: 0.1381, Val Class Acc: 0.7018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:58:35.332136: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:58:36.172650: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 0.6458\n",
            "Epoch 15/30 - Loss: 0.5150, Class Loss: 0.4960, Bbox Loss: 0.0190 - Val Loss: 0.6458, Val Class Loss: 0.5191, Val Bbox Loss: 0.1268, Val Class Acc: 0.7049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:58:58.901187: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:58:59.731242: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/30 - Loss: 0.5132, Class Loss: 0.4952, Bbox Loss: 0.0179 - Val Loss: 0.7148, Val Class Loss: 0.6297, Val Bbox Loss: 0.0851, Val Class Acc: 0.6862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:59:22.406430: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:59:23.132425: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 0.6422\n",
            "Epoch 17/30 - Loss: 0.5158, Class Loss: 0.4969, Bbox Loss: 0.0188 - Val Loss: 0.6422, Val Class Loss: 0.5183, Val Bbox Loss: 0.1239, Val Class Acc: 0.7049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-22 23:59:45.653510: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-22 23:59:46.376967: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/30 - Loss: 0.5252, Class Loss: 0.5056, Bbox Loss: 0.0196 - Val Loss: 1.2344, Val Class Loss: 0.7378, Val Bbox Loss: 0.4966, Val Class Acc: 0.5840\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:00:08.855518: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:00:09.648697: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/30 - Loss: 0.5193, Class Loss: 0.4997, Bbox Loss: 0.0195 - Val Loss: 0.8087, Val Class Loss: 0.6991, Val Bbox Loss: 0.1096, Val Class Acc: 0.6507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:00:31.709750: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:00:32.547438: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/30 - Loss: 0.5167, Class Loss: 0.4986, Bbox Loss: 0.0181 - Val Loss: 2.0705, Val Class Loss: 1.9794, Val Bbox Loss: 0.0911, Val Class Acc: 0.4880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:00:54.555070: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:00:55.342652: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/30 - Loss: 0.5230, Class Loss: 0.5047, Bbox Loss: 0.0183 - Val Loss: 0.8605, Val Class Loss: 0.7848, Val Bbox Loss: 0.0757, Val Class Acc: 0.6444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:01:18.323923: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:01:19.091688: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/30 - Loss: 0.5125, Class Loss: 0.4941, Bbox Loss: 0.0184 - Val Loss: 0.8882, Val Class Loss: 0.8245, Val Bbox Loss: 0.0637, Val Class Acc: 0.6309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:01:41.550782: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:01:42.337850: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/30 - Loss: 0.5110, Class Loss: 0.4935, Bbox Loss: 0.0175 - Val Loss: 1.8067, Val Class Loss: 1.7509, Val Bbox Loss: 0.0558, Val Class Acc: 0.5360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:02:04.369077: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:02:05.142832: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/30 - Loss: 0.5128, Class Loss: 0.4947, Bbox Loss: 0.0181 - Val Loss: 2.9652, Val Class Loss: 2.9078, Val Bbox Loss: 0.0574, Val Class Acc: 0.5778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:02:27.281626: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:02:28.042249: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/30 - Loss: 0.5199, Class Loss: 0.5009, Bbox Loss: 0.0190 - Val Loss: 0.8868, Val Class Loss: 0.8368, Val Bbox Loss: 0.0500, Val Class Acc: 0.6809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:02:50.094298: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:02:50.886131: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 0.5752\n",
            "Epoch 26/30 - Loss: 0.5114, Class Loss: 0.4932, Bbox Loss: 0.0182 - Val Loss: 0.5752, Val Class Loss: 0.5277, Val Bbox Loss: 0.0475, Val Class Acc: 0.6934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:03:14.022208: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:03:14.847387: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/30 - Loss: 0.5082, Class Loss: 0.4913, Bbox Loss: 0.0169 - Val Loss: 0.5761, Val Class Loss: 0.4993, Val Bbox Loss: 0.0768, Val Class Acc: 0.7018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:03:36.708061: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:03:37.468300: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 0.5467\n",
            "Epoch 28/30 - Loss: 0.5088, Class Loss: 0.4919, Bbox Loss: 0.0169 - Val Loss: 0.5467, Val Class Loss: 0.5011, Val Bbox Loss: 0.0456, Val Class Acc: 0.7081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:03:59.742061: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:04:00.551477: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/30 - Loss: 0.5085, Class Loss: 0.4918, Bbox Loss: 0.0167 - Val Loss: 0.5578, Val Class Loss: 0.5087, Val Bbox Loss: 0.0490, Val Class Acc: 0.7081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-23 00:04:22.815294: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "2025-03-23 00:04:23.576260: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "保存最佳模型，验证损失: 0.5427\n",
            "Epoch 30/30 - Loss: 0.5101, Class Loss: 0.4937, Bbox Loss: 0.0164 - Val Loss: 0.5427, Val Class Loss: 0.4868, Val Bbox Loss: 0.0558, Val Class Acc: 0.7049\n",
            "\n",
            "要查看TensorBoard，请在终端运行: tensorboard --logdir=logs/fit/20250322-235206\n"
          ]
        }
      ],
      "source": [
        "# 自定义训练循环\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "num_epochs = 30\n",
        "\n",
        "# 准备TensorBoard\n",
        "import os\n",
        "import datetime  # 确保导入了datetime模块\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "train_summary_writer = tf.summary.create_file_writer(os.path.join(log_dir, 'train'))\n",
        "val_summary_writer = tf.summary.create_file_writer(os.path.join(log_dir, 'validation'))\n",
        "\n",
        "# 训练步骤\n",
        "@tf.function\n",
        "def train_step(images, labels, bboxes):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # 前向传播\n",
        "        class_preds, bbox_preds = model(images, training=True)\n",
        "\n",
        "        # 计算损失\n",
        "        class_loss = tf.keras.losses.sparse_categorical_crossentropy(labels, class_preds)\n",
        "        # 使用tf.keras.losses.MSE而不是mean_squared_error\n",
        "        bbox_loss = tf.keras.losses.MSE(bboxes, bbox_preds)\n",
        "\n",
        "        # 总损失\n",
        "        total_loss = tf.reduce_mean(class_loss) + tf.reduce_mean(bbox_loss)\n",
        "\n",
        "    # 计算梯度\n",
        "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "    # 应用梯度\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return total_loss, tf.reduce_mean(class_loss), tf.reduce_mean(bbox_loss)\n",
        "\n",
        "# 验证步骤\n",
        "@tf.function\n",
        "def val_step(images, labels, bboxes):\n",
        "    # 前向传播\n",
        "    class_preds, bbox_preds = model(images, training=False)\n",
        "\n",
        "    # 计算损失\n",
        "    class_loss = tf.keras.losses.sparse_categorical_crossentropy(labels, class_preds)\n",
        "    # 使用tf.keras.losses.MSE而不是mean_squared_error\n",
        "    bbox_loss = tf.keras.losses.MSE(bboxes, bbox_preds)\n",
        "\n",
        "    # 总损失\n",
        "    total_loss = tf.reduce_mean(class_loss) + tf.reduce_mean(bbox_loss)\n",
        "\n",
        "    # 计算准确率\n",
        "    class_accuracy = tf.reduce_mean(\n",
        "        tf.cast(tf.equal(tf.argmax(class_preds, axis=1), tf.cast(labels, tf.int64)), tf.float32)\n",
        "    )\n",
        "\n",
        "    return total_loss, tf.reduce_mean(class_loss), tf.reduce_mean(bbox_loss), class_accuracy\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "history = {\n",
        "    'loss': [], 'class_loss': [], 'bbox_loss': [],\n",
        "    'val_loss': [], 'val_class_loss': [], 'val_bbox_loss': [], 'val_class_accuracy': []\n",
        "}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 训练\n",
        "    train_loss = []\n",
        "    train_class_loss = []\n",
        "    train_bbox_loss = []\n",
        "\n",
        "    for images, (labels, bboxes) in train_dataset:\n",
        "        total_loss, class_loss, bbox_loss = train_step(images, labels, bboxes)\n",
        "        train_loss.append(total_loss)\n",
        "        train_class_loss.append(class_loss)\n",
        "        train_bbox_loss.append(bbox_loss)\n",
        "\n",
        "    # 计算训练平均损失\n",
        "    avg_train_loss = tf.reduce_mean(train_loss)\n",
        "    avg_train_class_loss = tf.reduce_mean(train_class_loss)\n",
        "    avg_train_bbox_loss = tf.reduce_mean(train_bbox_loss)\n",
        "\n",
        "    # 验证\n",
        "    val_loss = []\n",
        "    val_class_loss = []\n",
        "    val_bbox_loss = []\n",
        "    val_class_accuracy = []\n",
        "\n",
        "    for val_images, (val_labels, val_bboxes) in val_dataset:\n",
        "        total_loss, class_loss, bbox_loss, class_accuracy = val_step(val_images, val_labels, val_bboxes)\n",
        "        val_loss.append(total_loss)\n",
        "        val_class_loss.append(class_loss)\n",
        "        val_bbox_loss.append(bbox_loss)\n",
        "        val_class_accuracy.append(class_accuracy)\n",
        "\n",
        "    # 计算验证平均损失\n",
        "    avg_val_loss = tf.reduce_mean(val_loss)\n",
        "    avg_val_class_loss = tf.reduce_mean(val_class_loss)\n",
        "    avg_val_bbox_loss = tf.reduce_mean(val_bbox_loss)\n",
        "    avg_val_class_accuracy = tf.reduce_mean(val_class_accuracy)\n",
        "\n",
        "    # 更新历史\n",
        "    history['loss'].append(avg_train_loss.numpy())\n",
        "    history['class_loss'].append(avg_train_class_loss.numpy())\n",
        "    history['bbox_loss'].append(avg_train_bbox_loss.numpy())\n",
        "    history['val_loss'].append(avg_val_loss.numpy())\n",
        "    history['val_class_loss'].append(avg_val_class_loss.numpy())\n",
        "    history['val_bbox_loss'].append(avg_val_bbox_loss.numpy())\n",
        "    history['val_class_accuracy'].append(avg_val_class_accuracy.numpy())\n",
        "\n",
        "    # 保存最佳模型\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        model.save('best_model.keras')\n",
        "        print(f\"保存最佳模型，验证损失: {best_val_loss:.4f}\")\n",
        "\n",
        "    # 记录到TensorBoard\n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', avg_train_loss, step=epoch)\n",
        "        tf.summary.scalar('class_loss', avg_train_class_loss, step=epoch)\n",
        "        tf.summary.scalar('bbox_loss', avg_train_bbox_loss, step=epoch)\n",
        "\n",
        "    with val_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', avg_val_loss, step=epoch)\n",
        "        tf.summary.scalar('class_loss', avg_val_class_loss, step=epoch)\n",
        "        tf.summary.scalar('bbox_loss', avg_val_bbox_loss, step=epoch)\n",
        "        tf.summary.scalar('class_accuracy', avg_val_class_accuracy, step=epoch)\n",
        "\n",
        "    # 打印进度\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
        "          f\"Loss: {avg_train_loss:.4f}, Class Loss: {avg_train_class_loss:.4f}, Bbox Loss: {avg_train_bbox_loss:.4f} - \"\n",
        "          f\"Val Loss: {avg_val_loss:.4f}, Val Class Loss: {avg_val_class_loss:.4f}, \"\n",
        "          f\"Val Bbox Loss: {avg_val_bbox_loss:.4f}, Val Class Acc: {avg_val_class_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\n要查看TensorBoard，请在终端运行: tensorboard --logdir={log_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00b0f43b",
      "metadata": {
        "id": "00b0f43b",
        "outputId": "d3a0fc96-6347-4461-c393-82fc5d3f871f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "模型文件存在，但格式可能不是SavedModel\n",
            "尝试直接从内存中导出模型...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "上述转换方法失败: 'Functional' object has no attribute '_get_save_spec'\n",
            "模型已保存为H5格式到 model.h5\n",
            "H5格式转换失败: Unknown layer: 'TrueDivide'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
            "权重保存和具体函数转换失败: The filename must end in `.weights.h5`. Received: filepath=model_weights.h5\n",
            "尝试重建模型...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "重建的模型已保存到 rebuilt_model.h5\n",
            "重建模型并保存失败: 'Functional' object has no attribute '_get_save_spec'\n",
            "模型权重已保存为NumPy数组到目录: model_weights_numpy\n",
            "权重总数: 266\n"
          ]
        }
      ],
      "source": [
        "# 使用已保存的权重和重建模型创建TFLite模型\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 1. 首先定义和重建模型\n",
        "def create_detection_model(input_shape=(224, 224, 3), num_classes=3):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        weights=None  # 不使用预训练权重\n",
        "    )\n",
        "\n",
        "    # 冻结基础模型的前几层\n",
        "    for layer in base_model.layers[:100]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "    # 分类头\n",
        "    classification_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='classification')(x)\n",
        "\n",
        "    # 边界框回归头\n",
        "    bbox_output = tf.keras.layers.Dense(4, name='bbox_regression')(x)\n",
        "\n",
        "    # 创建模型\n",
        "    return tf.keras.Model(inputs=inputs, outputs=[classification_output, bbox_output])\n",
        "\n",
        "# 2. 创建新模型实例\n",
        "new_model = create_detection_model()\n",
        "\n",
        "# 3. 从已保存的NumPy文件加载权重\n",
        "weight_dir = \"model_weights_numpy\"\n",
        "weights = []\n",
        "\n",
        "# 按顺序加载权重\n",
        "for i in range(266):  # 使用你打印的权重总数\n",
        "    weight_file = os.path.join(weight_dir, f\"weight_{i}.npy\")\n",
        "    if os.path.exists(weight_file):\n",
        "        weights.append(np.load(weight_file))\n",
        "    else:\n",
        "        print(f\"找不到权重文件: {weight_file}\")\n",
        "        break\n",
        "\n",
        "# 检查是否所有权重都加载成功\n",
        "if len(weights) == 266:\n",
        "    # 4. 将权重应用到新模型\n",
        "    try:\n",
        "        new_model.set_weights(weights)\n",
        "        print(\"成功将保存的权重应用到新模型\")\n",
        "\n",
        "        # 5. 使用最直接的方法转换为TFLite\n",
        "        # 通过具体输入和输出创建转换器\n",
        "        input_shape = [1, 224, 224, 3]  # 批次大小为1\n",
        "\n",
        "        # 创建转换用的输入数据\n",
        "        sample_input = np.random.random(input_shape).astype(np.float32)\n",
        "\n",
        "        # 使用具体函数进行转换\n",
        "        @tf.function\n",
        "        def serving_fn(x):\n",
        "            return new_model(x)\n",
        "\n",
        "        concrete_func = serving_fn.get_concrete_function(\n",
        "            tf.TensorSpec(input_shape, tf.float32))\n",
        "\n",
        "        converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "\n",
        "        try:\n",
        "            # 标准精度转换\n",
        "            tflite_model = converter.convert()\n",
        "            with open(\"detector_model.tflite\", \"wb\") as f:\n",
        "                f.write(tflite_model)\n",
        "            print(\"成功保存标准TFLite模型到 detector_model.tflite\")\n",
        "\n",
        "            # 尝试进行量化优化\n",
        "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "            try:\n",
        "                optimized_tflite_model = converter.convert()\n",
        "                with open(\"detector_model_optimized.tflite\", \"wb\") as f:\n",
        "                    f.write(optimized_tflite_model)\n",
        "                print(\"成功保存优化TFLite模型到 detector_model_optimized.tflite\")\n",
        "            except Exception as e:\n",
        "                print(f\"优化TFLite模型失败: {e}\")\n",
        "\n",
        "        except Exception as convert_error:\n",
        "            print(f\"TFLite转换失败: {convert_error}\")\n",
        "\n",
        "            # 备选方法：更简单的转换方式\n",
        "            try:\n",
        "                # 确保输入形状正确\n",
        "                dummy_input = tf.ones([1, 224, 224, 3], dtype=tf.float32)\n",
        "                # 确保模型可以正确推理\n",
        "                test_outputs = new_model(dummy_input)\n",
        "                print(f\"模型测试成功，输出形状: {[o.shape for o in test_outputs]}\")\n",
        "\n",
        "                # 尝试使用简单的转换方法\n",
        "                simple_converter = tf.lite.TFLiteConverter.from_keras_model(new_model)\n",
        "                simple_tflite_model = simple_converter.convert()\n",
        "\n",
        "                with open(\"detector_model_simple.tflite\", \"wb\") as f:\n",
        "                    f.write(simple_tflite_model)\n",
        "                print(\"成功使用简单方法保存TFLite模型到 detector_model_simple.tflite\")\n",
        "            except Exception as simple_error:\n",
        "                print(f\"简单TFLite转换也失败了: {simple_error}\")\n",
        "                print(\"请考虑使用以下方法直接在推理时加载权重:\")\n",
        "                print(\"\"\"\n",
        "                # 在推理代码中:\n",
        "                def load_model_from_weights():\n",
        "                    model = create_detection_model()\n",
        "                    weights = []\n",
        "                    for i in range(266):\n",
        "                        weights.append(np.load(f\"model_weights_numpy/weight_{i}.npy\"))\n",
        "                    model.set_weights(weights)\n",
        "                    return model\n",
        "\n",
        "                # 然后使用这个模型进行预测\n",
        "                model = load_model_from_weights()\n",
        "                predictions = model(image_batch)\n",
        "                \"\"\")\n",
        "    except Exception as e:\n",
        "        print(f\"应用权重到新模型失败: {e}\")\n",
        "else:\n",
        "    print(f\"无法加载所有权重，只找到 {len(weights)} 个权重文件，但需要 266 个\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "FTC_Limelight",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}